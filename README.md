# Arkham Contract Chat - AplicaciÃ³n Web

Chatbot especializado en contratos de arrendamiento desarrollado con Next.js 15, que utiliza el modelo fine-tuned de OpenAI entrenado especÃ­ficamente para responder preguntas sobre contratos legales.

## ğŸ“‹ DescripciÃ³n del Proyecto

Esta aplicaciÃ³n web es la interfaz de usuario del challenge de Arkham Intelligence, diseÃ±ada para demostrar las capacidades del modelo fine-tuned en un entorno de producciÃ³n. Permite a los usuarios interactuar mediante chat con un asistente especializado que comprende y responde preguntas sobre contratos de arrendamiento.

## ğŸš€ CaracterÃ­sticas

- **Chat en tiempo real** con streaming de respuestas
- **Interfaz moderna y responsiva** construida con Tailwind CSS
- **IntegraciÃ³n directa** con el modelo fine-tuned de OpenAI
- **Indicador de escritura** durante la generaciÃ³n de respuestas
- **Historial de conversaciÃ³n** persistente en la sesiÃ³n
- **API Routes optimizadas** para manejo eficiente de tokens

## ğŸ› ï¸ Stack TecnolÃ³gico

- **Framework:** Next.js 15 (App Router)
- **Lenguaje:** TypeScript
- **Estilos:** Tailwind CSS
- **LLM:** OpenAI GPT-4o-mini (Fine-tuned)
- **API:** OpenAI SDK v4
- **Despliegue:** Vercel-ready

## ğŸ“ Estructura del Proyecto

```
chat-arkham/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ chat/
â”‚   â”‚       â”œâ”€â”€ route.ts          # API endpoint principal (no-streaming)
â”‚   â”‚       â””â”€â”€ stream/
â”‚   â”‚           â””â”€â”€ route.ts      # API endpoint con streaming
â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”œâ”€â”€ page.tsx              # PÃ¡gina principal del chat
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â”œâ”€â”€ ChatInput.tsx     # Input de mensajes del usuario
â”‚   â”‚       â”œâ”€â”€ ChatMessage.tsx   # Componente de mensaje individual
â”‚   â”‚       â””â”€â”€ TypingIndicator.tsx # Indicador de "escribiendo..."
â”‚   â”œâ”€â”€ layout.tsx                # Layout principal de la app
â”‚   â”œâ”€â”€ page.tsx                  # Landing page
â”‚   â””â”€â”€ globals.css               # Estilos globales
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ constants.ts          # ConfiguraciÃ³n y constantes
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ openai.ts            # Cliente de OpenAI configurado
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ chat.ts              # Tipos TypeScript
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ validation.ts         # Validaciones y utilidades
â”‚
â””â”€â”€ public/                       # Recursos estÃ¡ticos
```

## ğŸš€ InstalaciÃ³n y Uso

### Prerrequisitos

- Node.js 18+ o compatible
- pnpm (recomendado) / npm / yarn
- API Key de OpenAI con acceso al modelo fine-tuned

### InstalaciÃ³n

1. Clonar el repositorio:

```bash
git clone https://github.com/Omarhersan/chat-arkham.git
cd chat-arkham
```

2. Instalar dependencias:

```bash
pnpm install
```

3. Configurar variables de entorno:

Crear archivo `.env.local`:

```env
OPENAI_API_KEY=tu_api_key_aqui
OPENAI_MODEL=ft:gpt-4o-mini-2024-07-18:personal:arkham-contract:CcK1RP96
```

### Desarrollo

Ejecutar el servidor de desarrollo:

```bash
pnpm dev
```

Abrir [http://localhost:3000](http://localhost:3000) en el navegador.

### ProducciÃ³n

Construir la aplicaciÃ³n:

```bash
pnpm build
```

Ejecutar en modo producciÃ³n:

```bash
pnpm start
```

## ğŸ¯ Hallazgos del Desarrollo

### 1. ImplementaciÃ³n de Streaming

**DesafÃ­o:** Implementar respuestas en tiempo real que mejoren la experiencia del usuario.

**SoluciÃ³n implementada:**
- API Route `/api/chat/stream` con `ReadableStream`
- Procesamiento de chunks del streaming de OpenAI
- Manejo de eventos SSE (Server-Sent Events) para actualizaciÃ³n incremental

**Aprendizaje:** El streaming mejora significativamente la percepciÃ³n de velocidad, especialmente en respuestas largas del modelo fine-tuned que pueden contener citas extensas de clÃ¡usulas contractuales.

### 2. GestiÃ³n de Contexto de ConversaciÃ³n

**DesafÃ­o:** Mantener coherencia en conversaciones multi-turno sin exceder lÃ­mites de tokens.

**ImplementaciÃ³n:**
- Historial de mensajes en estado del cliente (React)
- EnvÃ­o completo del historial en cada peticiÃ³n
- Sistema de prompts con rol "system" especializado

**LimitaciÃ³n identificada:** Sin implementar truncado de contexto aÃºn. Para producciÃ³n real se requerirÃ­a:
- LÃ­mite de mensajes en historial (ej: Ãºltimos 10 mensajes)
- Conteo de tokens para prevenir excesos
- Estrategia de resumen de conversaciÃ³n larga

### 3. OptimizaciÃ³n de UX con Indicadores Visuales

**Componentes clave:**
- `TypingIndicator`: AnimaciÃ³n durante generaciÃ³n de respuesta
- Scroll automÃ¡tico al Ãºltimo mensaje
- DiferenciaciÃ³n visual entre mensajes de usuario y asistente

**Impacto:** Reduce la percepciÃ³n de latencia y mejora la sensaciÃ³n de "conversaciÃ³n natural".

### 4. Arquitectura de API Routes

**DecisiÃ³n de diseÃ±o:** Dos endpoints separados
- `/api/chat/route.ts`: Respuesta completa (Ãºtil para testing)
- `/api/chat/stream/route.ts`: Respuesta con streaming (producciÃ³n)


### 5. ValidaciÃ³n y Manejo de Errores

**Implementaciones:**
- ValidaciÃ³n de mensajes vacÃ­os en cliente
- Manejo de errores de API con mensajes user-friendly

**Ãreas de mejora identificadas:**
- Rate limiting no implementado
- Falta manejo de errores especÃ­ficos de OpenAI (ej: model overload)
- Sin fallback a modelo base si fine-tuned falla


### 7. Rendimiento y OptimizaciÃ³n

**MÃ©tricas observadas:**
- Tiempo de primera respuesta (TTFR): ~800ms
- Streaming de chunks: ~50-100ms entre tokens
- TamaÃ±o de bundle: Optimizado con App Router de Next.js

**Estrategias aplicadas:**
- Server Components por defecto para reducir JS del cliente
- Lazy loading de componentes pesados (no aplicado aÃºn)
- CSS optimizado con Tailwind + purge

## ğŸ”§ ConfiguraciÃ³n del Modelo

El archivo `lib/config/constants.ts` define el comportamiento del chatbot:

```typescript
export const CHAT_CONFIG = {
  model: process.env.OPENAI_MODEL || 'ft:gpt-4o-mini-2024-07-18:personal:arkham-contract:CcK1RP96',
  systemPrompt: 'Eres un asistente especializado en contratos de arrendamiento...',
  maxTokens: 1000,
  temperature: 0.7,
};
```

**ParÃ¡metros ajustables:**
- `temperature`: 0.7 para balance entre creatividad y precisiÃ³n
- `maxTokens`: 1000 para permitir citas extensas de contratos
- `systemPrompt`: Define comportamiento y tono del asistente

## ğŸ“Š MÃ©tricas de la AplicaciÃ³n

**Rendimiento:**
- Lighthouse Score: 95+ (Performance)
- First Contentful Paint: <1s
- Time to Interactive: <2s


## ğŸ“ Mejoras Futuras

### Corto plazo:
1. **GestiÃ³n de contexto mejorada**
   - Implementar ventana deslizante de mensajes
   - Conteo de tokens con `tiktoken`
   - Resumen automÃ¡tico de conversaciones largas

2. **Funcionalidades de chat avanzadas**
   - Botones de sugerencias de preguntas
   - Exportar conversaciÃ³n a PDF
   - Compartir chat mediante URL

3. **Robustez**
   - Rate limiting por usuario
   - Manejo robusto de errores de API
   - Retry logic con backoff exponencial

## ğŸ”— Recursos

- [DocumentaciÃ³n de Next.js](https://nextjs.org/docs)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [Tailwind CSS Docs](https://tailwindcss.com/docs)
- Despliegue en [Vercel](https://chat-arkham.vercel.app/chat)

## ğŸ“ Notas de Desarrollo

**Versiones utilizadas:**
- Next.js: 15.0.3
- React: 19.0.0
- TypeScript: 5.6.3
- OpenAI SDK: 4.73.0

**Consideraciones:**
- App Router de Next.js (no Pages Router)
- Modo estricto de TypeScript habilitado
- ESLint configurado con reglas recomendadas
